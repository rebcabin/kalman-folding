#+TITLE: Kalman Folding 4: Streams and Observables (Review Draft)
#+SUBTITLE: Extracting Models from Data, One Observation at a Time
#+AUTHOR: Brian Beckman
#+DATE: <2016-05-03 Tue>
#+EMAIL: bbeckman@34363bc84acc.ant.amazon.com
#+OPTIONS: ':t *:t -:t ::t <:t H:3 \n:nil ^:t arch:headline author:t c:nil
#+OPTIONS: d:(not "LOGBOOK") date:t e:t email:nil f:t inline:t
#+OPTIONS: num:t p:nil pri:nil stat:t tags:t tasks:t tex:t timestamp:t toc:t
#+OPTIONS: todo:t |:t
#+SELECT_TAGS: export
#+STARTUP: indent
#+LaTeX_CLASS_OPTIONS: [10pt,oneside,x11names]
#+LaTeX_HEADER: \usepackage{geometry}
#+LaTeX_HEADER: \usepackage{amsmath}
#+LaTeX_HEADER: \usepackage{amssymb}
#+LaTeX_HEADER: \usepackage{amsfonts}
#+LaTeX_HEADER: \usepackage{palatino}
#+LaTeX_HEADER: \usepackage{siunitx}
#+LaTeX_HEADER: \usepackage{esdiff}
#+LaTeX_HEADER: \usepackage{xfrac}
#+LaTeX_HEADER: \usepackage{nicefrac}
#+LaTeX_HEADER: \usepackage{faktor}
#+LaTeX_HEADER: \usepackage[euler-digits,euler-hat-accent]{eulervm}
#+OPTIONS: toc:2

* COMMENT Preliminaries

This section is just about setting up org-mode. It shouldn't export to the
typeset PDF and HTML.

#+BEGIN_SRC emacs-lisp :exports results none
  (defun update-equation-tag ()
    (interactive)
    (save-excursion
      (goto-char (point-min))
      (let ((count 1))
        (while (re-search-forward "\\tag{\\([0-9]+\\)}" nil t)
          (replace-match (format "%d" count) nil nil nil 1)
          (setq count (1+ count))))))
  (update-equation-tag)
  (setq org-confirm-babel-evaluate nil)
  (org-babel-map-src-blocks nil (org-babel-remove-result))
  (slime)
#+END_SRC

#+RESULTS:
: #<buffer *inferior-lisp*>

* Abstract

In /Kalman Folding, Part 1/,[fn:klfl] we present basic, static Kalman filtering
as a functional fold, highlighting the unique advantages of this form for
deploying test-hardened code verbatim in harsh, mission-critical environments.
In that paper, all examples folded over arrays in memory for convenience and
repeatability. That is an example of developing filters in a friendly
environment.

Here, we prototype a couple of less friendly environments and demonstrate
exactly the same Kalman accumulator function at work. These less friendly
environments are
- lazy streams, where new observations are computed on demand but never fully
  realized in memory, thus not available for inspection in a debugger
- asynchronous observables, where new observations are delivered at arbitrary
  times from an external source, thus not available for replay once consumed by
  the filter

Streams are a natural fit for integration of differential equations, which often
arise in applications. As such, they enable unique modularization for all kinds
of filters, including non-linear Extended Kalman Filters.

The fact that the Kalman accumulator function gives bit-for-bit identical
results in all cases gives us high confidence that code developed in friendly
environments will behave as intended in unfriendly environments. This level of
repeatability is available /only/ because of functional decomposition, which
minimizes the coupling between the accumulator function and the environment and
makes it possible to deploy exactly the same code, without even recompilation,
in all environments.

* Kalman Folding in the Wolfram Language

In this series of papers, we use the Wolfram language[fn:wolf] because it excels
at concise expression of mathematical code. All examples in these papers can be
directly transcribed to any modern mainstream language that supports closures.
For example, it is easy to write them in C++11 and beyond, Python, any modern
Lisp, not to mention Haskell, Scala, Erlang, and OCaml. Many can be written
without full closures; function pointers will suffice, so they are easy to write
in C. It's also not difficult to add extra arguments to simulate just enough
closure-like support in C to write the rest of the examples in that language.


In /Kalman Folding/,[fn:klfl] we found the following elegant formulation for the
accumulator function of a fold that implements the static Kalman filter:

#+BEGIN_LaTeX
\begin{equation}
\label{eqn:kalman-cume-definition}
\text{kalmanStatic}
\left(
\mathbold{Z}
\right)
\left(
\left\{
\mathbold{x},
\mathbold{P}
\right\},
\left\{
\mathbold{A},
\mathbold{z}
\right\}
\right) =
\left\{
\mathbold{x}+
\mathbold{K}\,
\left(
\mathbold{z}-
\mathbold{A}\,
\mathbold{x}
\right),
\mathbold{P}-
\mathbold{K}\,
\mathbold{D}\,
\mathbold{K}^\intercal
\right\}
\end{equation}
#+END_LaTeX

\noindent where

#+BEGIN_LaTeX
\begin{align}
\label{eqn:kalman-gain-definition}
\mathbold{K}
&=
\mathbold{P}\,
\mathbold{A}^\intercal\,
\mathbold{D}^{-1} \\
\label{eqn:kalman-denominator-definition}
\mathbold{D}
&= \mathbold{Z} +
\mathbold{A}\,
\mathbold{P}\,
\mathbold{A}^\intercal
\end{align}
#+END_LaTeX

\noindent and all quantities are matrices:

- $\mathbold{z}$ is a  ${b}\times{1}$ column vector containing one multidimensional observation
- $\mathbold{x}$ is an ${n}\times{1}$ column vector of /model states/
- $\mathbold{Z}$ is a  ${b}\times{b}$ matrix, the covariance of
  observation noise
- $\mathbold{P}$ is an ${n}\times{n}$ matrix, the theoretical
  covariance of $\mathbold{x}$
- $\mathbold{A}$ is a  ${b}\times{n}$ matrix, the /observation partials/
- $\mathbold{D}$ is a  ${b}\times{b}$ matrix, the Kalman denominator
- $\mathbold{K}$ is an ${n}\times{b}$ matrix, the Kalman gain

In physical or engineering applications, these quantities carry physical
dimensions of units of measure in addition to their matrix dimensions as numbers
of rows and columns. 
If the physical and matrix dimensions of 
$\mathbold{x}$ 
are
$\left[\left[\mathbold{x}\right]\right]
\stackrel{\text{\tiny def}}{=}
(\mathcal{X}, n\times{1})$
and of 
$\mathbold{z}$ 
are
$\left[\left[\mathbold{z}\right]\right]
\stackrel{\text{\tiny def}}{=}
(\mathcal{Z}, b\times{1})$, then

#+BEGIN_LaTeX
\begin{equation}
\label{eqn:dimensional-breakdown}
\begin{array}{lccccr}
\left[\left[\mathbold{Z}\right]\right]                                       &=& (&\mathcal{Z}^2            & b\times{b}&) \\
\left[\left[\mathbold{A}\right]\right]                                       &=& (&\mathcal{Z}/\mathcal{X}  & b\times{n}&) \\
\left[\left[\mathbold{P}\right]\right]                                       &=& (&\mathcal{X}^2            & n\times{n}&) \\
\left[\left[\mathbold{A}\,\mathbold{P}\,\mathbold{A}^\intercal\right]\right] &=& (&\mathcal{Z}^2            & b\times{b}&) \\
\left[\left[\mathbold{D}\right]\right]                                       &=& (&\mathcal{Z}^2            & b\times{b}&) \\
\left[\left[\mathbold{P}\,\mathbold{A}^\intercal\right]\right]               &=& (&\mathcal{X}\,\mathcal{Z} & n\times{b}&) \\
\left[\left[\mathbold{K}\right]\right]                                       &=& (&\mathcal{X}/\mathcal{Z}  & n\times{b}&)
\end{array}
\end{equation}
#+END_LaTeX

Dimensional arguments, regarding both matrix dimensions and physical dimensions,
are invaluable for checking code and derivations in this topic at-large.

** A Test Example

In the following  example, the observations $\mathbold{z}$ are
$1\times{1}$ matrices, equivalent to scalars, so $b=1$.

The function in equation \ref{eqn:kalman-cume-definition}
/lambda-lifts/[fn:lmlf] $\mathbold{Z}$, meaning that it is necessary to call
/kalmanStatic/ with a constant $\mathbold{Z}$ to get the actual accumulator
function used in folds. This is desirable to reduce coupling between the
accumulator function and its calling environment. 

In Wolfram, this function is

#+BEGIN_LaTeX
\begin{verbatim}
kalmanStatic[Zeta_][{x_, P_}, {A_, z_}] :=
 Module[{D, K},
  D = Zeta + A.P.Transpose[A];
  K = P.Transpose[A].Inverse[D];
  {x2 + K.(z - A.x), P - K.D.Transpose[K]}]
\end{verbatim}
#+END_LaTeX

We test it on a small case

#+BEGIN_LaTeX
\begin{verbatim}
Fold[kalmanStatic[IdentityMatrix[1]],
  {ColumnVector[{0, 0, 0, 0}], IdentityMatrix[4]*1000.0},
  {{{{1,  0., 0.,  0.}}, { -2.28442}}, 
   {{{1,  1., 1.,  1.}}, { -4.83168}}, 
   {{{1, -1., 1., -1.}}, {-10.46010}}, 
   {{{1, -2., 4., -8.}}, {  1.40488}}, 
   {{{1,  2., 4.,  8.}}, {-40.8079}}}
  ] // Chop
~~>
\end{verbatim}
#+END_LaTeX

#+BEGIN_LaTeX
\begin{align}
\label{eqn:kalman-filter-results}
\mathbold{x} &=
\begin{bmatrix}
 -2.97423 \\
  7.2624  \\
 -4.21051 \\
 -4.45378 \\
\end{bmatrix}
\\
\notag
\mathbold{P} &=
\begin{bmatrix}
 0.485458 & 0 & -0.142778 & 0 \\
 0 & 0.901908 & 0 & -0.235882 \\
 -0.142778 & 0 & 0.0714031 & 0 \\
 0 & -0.235882 & 0 & 0.0693839 \\
\end{bmatrix}
\end{align}
#+END_LaTeX

\noindent expecting results within one or two standard deviations of the ground
truth $\aleph=\begin{bmatrix}-3& 9& -4& -5\end{bmatrix}^\intercal$, where the
standard deviations can be found as square roots of the diagonal
elements of $\mathbold{P}$. For details about this test case, see the first
paper in the series, /Kalman Folding, Part 1/.[fn:klfl]

Below, we reproduce these values exactly, to the bit level, by running
/kalmanStatic/ over lazy streams and asynchronous observables.

* Types for Kalman Folding

Kalman and all its variants are examples of /statistical function inversion./ We
have models that predict outcomes from inputs; we observe outcomes and want
estimates of the inputs. Structurally, all such incremental model inversions
take a pair of a state estimate (with uncertainty) and an observation, and
produce a new state estimate (with uncertainty). Such an inverted model has
signature, using a type notation similar to that of Haskell or Scala

#+BEGIN_LaTeX
\begin{equation*}
\textrm{inverted-model}
\left[S,T\right]
::
\left(S\rightarrow{T}\rightarrow{S}\right)
\end{equation*}
#+END_LaTeX

\noindent where the
return type is on the far right and the other types that appear before arrows
are the types of input arguments.
This function signature is exactly that required for the first argument of a
functional fold (more precisely, a /left/ fold). The signature of /fold/ is as
follows:

#+BEGIN_LaTeX
\begin{equation*}
\textrm{fold}
\left[S,T\right]
::
\left(S\rightarrow{T}\rightarrow{S}\right)
\rightarrow{S}
\rightarrow{\textrm{Sequence}\left[T\right]}
\rightarrow{S}
\end{equation*}
#+END_LaTeX

Read this, abstractly, as follows

#+BEGIN_QUOTE
\emph{Fold} over types $S$ and $T$ is a function that
takes three arguments:
1. another function (called the /accumulator function/)
2. an initial instance of type $S$
3. a sequence of instances of type $T$
and produces an instance of type $S$. The
accumulator function, in turn, is a binary function that takes an $S$ and a $T$ and
produces an $S$.
#+END_QUOTE

More concretely, In the context of Kalman filtering:

#+BEGIN_LaTeX
\begin{equation*}
\text{AccumulatorFunction}
::
\text{Accumulation}
\rightarrow
\text{Observation}
\rightarrow
\text{Accumulation}
\end{equation*}
#+END_LaTeX

\noindent where the types /Accumulation/ and /Observation/ are arbitrary. 

It's the job of /Fold/ to pass the elements of the input sequence to the
accumulator function one observation at a time, and to maintain and ultimately
return the final accumulation. The second argument to /Fold/ is
the desired, initial value of the accumulation. The
third and final argument to /Fold/ is the sequence of observations, of type
$\text{Sequence}\left[\,\text{Observation}\,\right]$

/Fold/ looks like a trinary function of an accumulator function, an
initial accumulation, and a sequence, yielding an accumulation. Folds thus have
the following type:

#+BEGIN_LaTeX
\begin{equation*}
\text{Fold :: }
\text{AccumulatorFunction}
\rightarrow
\text{Accumulation}
\rightarrow
\text{Sequence}\left[\,\text{Observation}\,\right]
\rightarrow
\text{Accumulation}
\end{equation*}
#+END_LaTeX

\noindent where /Sequence/ can be /List/, /Stream/, /Observable/, or any type
that can be accessed sequentially. 

* Over Lazy Streams and Asynchronous Observables

The accumulator function knows nothing about the source of the observations. If
we can figure out how to implement /Fold/ and /FoldList/ for things other than
/List/, we will have Kalman filtering over those sources, too.

The following are research-grade sketches of implementations of /Fold/ over lazy
streams[fn:musc] and asynchronous observables.[fn:intr] They provide just enough
to support the Kalman-folding examples.

** Folding Over Lazy Streams

Represent a lazy stream as a pair of a value and a /thunk/ (function of
no arguments).[fn:cons] The thunk must produce another lazy stream when called. Such
a stream can be infinite in abstract length because the elements of the stream are only
concretized in memory when demanded by calling thunks.

Streams are a natural fit for integrals of differential equations. We see in
other papers of this series how we can use them to deeply modularize filters
over rich non-linear models. In this paper, we show only how to fold a linear
Kalman filter over a stream.

By convention, a finite stream has a ~Null~ thunk at the end. Thus, the empty
stream, obtained by invoking such a thunk, is ~Null[]~, with square brackets
denoting invocation with no arguments.

One of Wolfram's notations for a literal thunk is an expression with an
ampersand in postfix position. An ampersand turns the expression to its left
into a thunk. For instance, here's a function that returns an infinite stream of
natural numbers starting at $n$:

#+BEGIN_LaTeX
\begin{verbatim}
integersFrom[n_Integer] := {n, integersFrom[n + 1] &}
\end{verbatim}
#+END_LaTeX

Calling, say, ~integersFrom[42]~ produces ~{42, integersFrom[42 + 1]&}~, a pair
of an integer, $42$, and another stream, ~integersFrom[42+1]&~. We get the
stream by extracting the second part of the pair /via/ Wolfram's double-bracket notation

#+BEGIN_LaTeX
\begin{verbatim}
integersFrom[42][[2]] ~~> integersFrom[42 + 1]&
\end{verbatim}
#+END_LaTeX

\noindent and then call it with empty brackets (it's a thunk, and takes no
arguments):

#+BEGIN_LaTeX
\begin{verbatim}
integersFrom[42][[2]][] ~~> {43, integersFrom[43 + 1]&}
\end{verbatim}
#+END_LaTeX

\noindent and so on. We can get a few more by repeating the process

#+BEGIN_LaTeX
\begin{verbatim}
integersFrom[42][[2]][][[2]][][[2]][] ~~> {45, integersFrom[45 + 1]&}
\end{verbatim}
#+END_LaTeX

\noindent but the best way to extract values from streams is to write recursive
functions to demand any number of elements from the head. The variety of such
functions, which include /map/, /select/, /fold/, is well known, large, and
identical across lists, streams, observables, and, in fact, any collection that
can support a /next/ operator. A good, contemporary full-service library for
collection types is LINQ's Standard Query Operators (SQO),[fn:lsqo]. If building
up a library from the present prototype level into something of product grade,
presentable to intolerant users, the SQO are an excellent framework to emulate.

As another example, the following function, when called with an appropriate
input, say the $2\times{2}$ identity matrix, returns a lazy stream of matrices
full of Fibonacci numbers:

#+BEGIN_LaTeX
\begin{verbatim}
fs[f_] := {f, fs[{{0, 1}, {1, 1}}.f] &}
\end{verbatim}
#+END_LaTeX

Here is an explicit invocation a few values down:

#+BEGIN_LaTeX
\begin{verbatim}
fs[IdentityMatrix[2]][[2]][][[2]][][[2]][][[2]][][[2]][][[2]][][[
        2]][][[2]][][[2]][][[2]][]
~~>
\end{verbatim}
\begin{equation*}
\begin{Bmatrix}
\begin{pmatrix} 34 & 55 \\ 55 & 89 \end{pmatrix},
fs
\begin{bmatrix}
\begin{pmatrix} 34 & 55 \\ 55 & 89 \end{pmatrix} \cdot
\begin{pmatrix} 0 & 1 \\ 1 & 1 \end{pmatrix} 
\end{bmatrix}\, \&
\end{Bmatrix}
\end{equation*}
#+END_LaTeX

\noindent the point being that lazy streams are versatile. 

We now write bi-directional conversions between streams and lists so we can test
an example, then we write /foldStream/.

*** Disperse :: List $\rightarrow$ Stream

We'll need a way to convert a list into a stream.  There are three cases: an
empty list, a singleton list, and the inductive or recursive  case.

#+BEGIN_LaTeX
\begin{verbatim}
disperse[{}] := Null[]; (* empty list yields empty stream       *)
disperse[{x_}] := {x, Null}; (* the stream for a singleton list *)
disperse[{v_, xs__}] := {v, disperse[{xs}] &}; (* recursion     *)
\end{verbatim}
#+END_LaTeX

*** Reify :: Stream $\rightarrow$ List

We need to go the other way, too; don't call this on a stream of infinite length:

#+BEGIN_LaTeX
\begin{verbatim}
reify[Null[]] := {};         (* produce empty list from empty stream *)
rify[{v_, Null}] := {v};     (* singleton list from singleton stream *)
reify[{v_, thunk_}] := Join[{v}, reify[thunk[]]]; (* recursion       *)
\end{verbatim}
#+END_LaTeX

*** foldStream 

Our equivalent for Wolfram's /FoldList/ is /foldStream/.[fn:uncl] Its type is similar

#+BEGIN_LaTeX
\begin{align*}
\text{foldStream :: }
\text{AccumulatorFunction}
\rightarrow
\text{Accumulation}\\
\rightarrow
\text{Stream}\left[\,\text{Observation}\,\right]
\rightarrow
\text{Stream}\left[\,\text{Accumulation}\,\right]
\end{align*}
#+END_LaTeX

Here is an implementation:

#+BEGIN_LaTeX
\begin{verbatim}
foldStream[f_, s_, Null[]] := (* acting on an empty stream *)
  {s, Null}; (* produce a singleton stream containing 's'  *)
foldStream[f_, s_, {z_, thunk_}] :=
  (* pass in a new thunk that recurses on the old thunk    *)
  {s, foldStream[f, f[s, z], thunk[]] &};
\end{verbatim}
#+END_LaTeX

*** Test

Test it over the /dispersion/ of the example data:

#+BEGIN_LaTeX
\begin{verbatim}
foldStream[
  kalmanStatic[IdentityMatrix[1]], (* same 'kalmanStatic;' no changes *)
  {ColumnVector[{0, 0, 0, 0}], IdentityMatrix[4]*1000.0},
  disperse[{{{{1,  0., 0.,  0.}}, { -2.28442}}, 
            {{{1,  1., 1.,  1.}}, { -4.83168}}, 
            {{{1, -1., 1., -1.}}, {-10.46010}}, 
            {{{1, -2., 4., -8.}}, {  1.40488}}, 
            {{{1,  2., 4.,  8.}}, {-40.8079}}}]
  ] // reify
\end{verbatim}
#+END_LaTeX

The only changes to the earlier fold over lists is the initial call of /disperse/ to
convert the test case into a stream, and the final postfix call ~// reify~
to turn the result back into a list for display. The final results are identical
to those in equation \ref{eqn:kalman-filter-results}, but we see all the
intermediate results as well, confirming that Kalman folds over observations one
at a time. We would have seen exactly the same output had we called /FoldList/
instead of /Fold/ over lists above.

#+BEGIN_LaTeX
\begin{equation}
\label{eql:full-big-results}
\begin{pmatrix}
\begin{bmatrix}
 0 \\
 0 \\
 0 \\
 0 \\
\end{bmatrix}
&
\begin{bmatrix}
 1000. & 0 & 0 & 0 \\
 0 & 1000. & 0 & 0 \\
 0 & 0 & 1000. & 0 \\
 0 & 0 & 0 & 1000. \\
\end{bmatrix}
\\ & \\
\begin{bmatrix}
 -2.28214 \\
 0 \\
 0 \\
 0 \\
\end{bmatrix}
&
\begin{bmatrix}
 0.999001 & 0 & 0 & 0 \\
 0 & 1000. & 0 & 0 \\
 0 & 0 & 1000. & 0 \\
 0 & 0 & 0 & 1000. \\
\end{bmatrix}
\\ \\
\begin{bmatrix}
 -2.28299 \\
 -0.849281 \\
 -0.849281 \\
 -0.849281 \\
\end{bmatrix}
&
\begin{bmatrix}
 0.998669 & -0.332779 & -0.332779 & -0.332779 \\
 -0.332779 & 666.889 & -333.111 & -333.111 \\
 -0.332779 & -333.111 & 666.889 & -333.111 \\
 -0.332779 & -333.111 & -333.111 & 666.889 \\
\end{bmatrix}
\\ \\
\begin{bmatrix}
 -2.28749 \\
 1.40675 \\
 -5.35572 \\
 1.40675 \\
\end{bmatrix}
&
\begin{bmatrix}
 0.998004 & 0 & -0.997506 & 0 \\
 0 & 500.125 & 0 & -499.875 \\
 -0.997506 & 0 & 1.49676 & 0 \\
 0 & -499.875 & 0 & 500.125 \\
\end{bmatrix}
\\ \\
\begin{bmatrix}
 -2.29399 \\
 7.92347 \\
 -5.34488 \\
 -5.1154 \\
\end{bmatrix}
&
\begin{bmatrix}
 0.997508 & 0.49762 & -0.996678 & -0.498035 \\
 0.49762 & 1.3855 & -0.829836 & -0.719881 \\
 -0.996678 & -0.829836 & 1.49538 & 0.830528 \\
 -0.498035 & -0.719881 & 0.830528 & 0.553787 \\
\end{bmatrix}
\\ \\
\begin{bmatrix}
 -2.97423 \\
 7.2624 \\
 -4.21051 \\
 -4.45378 \\
\end{bmatrix}
&
\begin{bmatrix}
 0.485458 & 0 & -0.142778 & 0 \\
 0 & 0.901908 & 0 & -0.235882 \\
 -0.142778 & 0 & 0.0714031 & 0 \\
 0 & -0.235882 & 0 & 0.0693839 \\
\end{bmatrix}
\end{pmatrix}
\end{equation}
#+END_LaTeX

** Folding Over an Asynchronous Observable

Just as /FoldList/ produces a list from a list, and /foldStream/ produces a
stream from a stream, /foldObservable/ produces an observable from an
observable. Its full signature is

#+BEGIN_LaTeX
\begin{align*}
\text{foldObservable :: }
\text{AccumulatorFunction}
\rightarrow
\text{Accumulation}\\
\rightarrow
\text{Observable}\left[\,\text{Observation}\,\right]
\rightarrow
\text{Observable}\left[\,\text{Accumulation}\,\right]
\end{align*}
#+END_LaTeX

Lists provide data elements distributed in space (memory). Lazy streams provide
data in constant memory, but distributed in a kind of virtual time, delivered
when demanded, the way a debugger fakes time. Observables provide data elements
distributed asynchronously in real time. To consume elements of an observable,
subscribe an observer to it. An observer has a callback function, and the
observable will invoke the callback for each observation, asynchronously, as the
observation arrives. The callback function takes a single argument that receives
the observation.

#+BEGIN_COMMENT
One pretty way to consume elements from a list is with a function like Scala's
/foreach/,[fn:scla] which takes a callback function and calls it for each
element in the sequence. This is /just like/ the /Subscribe/ function of the
standard Observable interface, so much so that we may regard /foreach/ and
/Subscribe/ as semantically identical. Thus, building a simulacrum of Observable
for the sake of testing Kalman folding is not much harder than writing
/foreach/. We do  not develop observables fully, here. For that, see a
reference like Campbell's /Intro to Rx/.[fn:intr] Instead, we content ourselves
with a simulacrum and, as with Lazy Streams, a way to get back and forth from
Wolfram's lists.
#+END_COMMENT

We do not develop observables fully, here. For that, see a reference like
Campbell's /Intro to Rx/.[fn:intr] Instead, we content ourselves with just
enough to demonstrate Kalman folding over them and, as with lazy streams, a way
to get back and forth from lists.

We model observables as stateful thunks that produce new values every time
they're invoked, then invoke the thunks inside asynchronous Wolfram tasks that
start at the moment some observer subscribes.[fn:cold]

*** Subscribe :: Observable $\rightarrow$ Observer $\rightarrow$ Null

Wolfram supplies a primitive, /RunScheduledTask/, for evaluating expressions
asynchronously, once per second by default. The expression that we pass to
/RunScheduledTask/, just calls the observer on the evaluated observable:

#+BEGIN_LaTeX
\begin{verbatim}
subscribe[observable_, observer_] :=
  RunScheduledTask[observer[observable[]]];
\end{verbatim}
#+END_LaTeX

*** Dispense :: List $\rightarrow$ Observable

The following is a specification of a task to run. Nothing happens till you
subscribe something to it. 

#+BEGIN_LaTeX
\begin{verbatim}
dispense[aList_List] :=
 Module[{state = aList},
  If[{} === state,
    Null, (* empty obs from empty list *)
    (state = Rest[state]; First[state]]);] &]
\end{verbatim}
#+END_LaTeX

*** Harvest :: Observable $\rightarrow$ List

Set up a conventional, external variable, ~r$~, so that we can interactively
look at the results in a Wolfram ~Dynamic[r$]~ form. Our /harvest/ 
subscribes an observer that appends observations to a list held in ~r$~.
Semicolon-separated expressions are sequenced, as with Scheme's ~begin~ or
Lisp's ~progn~.

#+BEGIN_LaTeX
\begin{verbatim}
harvest[obl_] :=
  (r$ = {};
   subscribe[obl, Function[v, If[v =!= Null, AppendTo[r$, v]]]]);
\end{verbatim}
#+END_LaTeX

We must eventually clean up the tasks and the external variable.

#+BEGIN_LaTeX
\begin{verbatim}
cleanup[] := (ClearAll[r$];
              RemoveScheduledTask[ScheduledTasks[]];);
\end{verbatim}
#+END_LaTeX

*** foldObservable 

The concrete type of /foldObservable/ is obvious: just replace /Stream/ with
/Observable/ in a copy of the type of /foldStream/.

#+BEGIN_LaTeX
\begin{align*}
\text{foldObservable :: }
\text{AccumulatorFunction}
\rightarrow
\text{Accumulation}\\
\rightarrow
\text{Observable}\left[\,\text{Observation}\,\right]
\rightarrow
\text{Observable}\left[\,\text{Accumulation}\,\right]
\end{align*}
#+END_LaTeX

One might ask about the appropriate generalization of higher-order types like
this, where we could go up a level, parameterize on types like /Stream/ and
/Observable/, and make the concrete types of /foldStream/ and /foldObservable/
instances of that higher, parameterized type. This is a sensible question, and
the answer leads to category theory and monads,[fn:mond] out of scope for this
paper.

This implementation isn't hygienic: it uses global variables (suffixed with ~$~
signs). It's just enough to test Kalman folding over observables.

#+BEGIN_LaTeX
\begin{verbatim}
foldObservable[f_, s_, obl_] :=
 Module[{newObl, s$ = s},
  newObl[] := With[{result = s$},
    s$ = f[s$, obl[]];
    result];
  newObl] (* return new observable *)
\end{verbatim}
#+END_LaTeX

*** Test

The following call has the same shape as our call of /foldStream/ above, except
calling /dispense/ instead of /disperse/ and /harvest/ instead of /reify/.

#+BEGIN_LaTeX
\begin{verbatim}
Dynamic[r$]
foldObservable[
  kalmanStatic[IdentityMatrix[1]],
  {ColumnVector[{0, 0, 0, 0}], IdentityMatrix[4]*1000.0},
  dispense[{{{{1,  0., 0.,  0.}}, { -2.28442}}, 
            {{{1,  1., 1.,  1.}}, { -4.83168}}, 
            {{{1, -1., 1., -1.}}, {-10.46010}}, 
            {{{1, -2., 4., -8.}}, {  1.40488}}, 
            {{{1,  2., 4.,  8.}}, {-40.8079}}}]
  ] // harvest;
r$
\end{verbatim}
#+END_LaTeX

The results are exactly the same as in equation \ref{eql:full-big-results}. 

* Concluding Remarks

With prototypes for /foldStream/ and /foldObservable/, we have demonstrated
Kalman folding with exactly the same accumulator function over wildly different
data-delivery environments. This demonstrates the primary thesis of this series
of papers: that writing filters as functional folds enables verbatim deployment
of code in both friendly, synchronous environments with all data in memory, and
unfriendly asynchronous environments using only constant memory. Verbatim means
with no changes at all, not even recompilation. 

We have tested these prototypes against bigger
examples like the tracking example[fn:klf2] and the accelerometer
example,[fn:klfl] and there are no surprises.

[fn:affn] https://en.wikipedia.org/wiki/Affine_transformation
[fn:bars] Bar-Shalom, Yaakov, /et al/. Estimation with applications to tracking and navigation. New York: Wiley, 2001.
[fn:bier] http://tinyurl.com/h3jh4kt
[fn:bssl] https://en.wikipedia.org/wiki/Bessel's_correction
[fn:busi] https://en.wikipedia.org/wiki/Business_logic
[fn:cdot] We sometimes use the center dot or the $\times$ symbols to clarify
matrix multiplication. They have no other significance and we can always write
matrix multiplication just by juxtaposing the matrices.
[fn:clos] https://en.wikipedia.org/wiki/Closure_(computer_programming)
[fn:cold] This convention only models so-called /cold observables/, but it's enough to demonstrate Kalman's working over them.
[fn:cons] This is quite similar to the standard --- not  Wolfram's --- definition of a list as a pair of a value and of another list.
[fn:cova] We use the terms /covariance/ for matrices and /variance/ for scalars.
[fn:csoc] https://en.wikipedia.org/wiki/Separation_of_concerns
[fn:ctsc] https://en.wikipedia.org/wiki/Catastrophic_cancellation
[fn:dstr] http://tinyurl.com/ze6qfb3
[fn:elib] Brookner, Eli. Tracking and Kalman Filtering Made Easy, New York: Wiley, 1998. http://tinyurl.com/h8see8k
[fn:fldl] http://tinyurl.com/jmxsevr
[fn:fwik] https://en.wikipedia.org/wiki/Fold_%28higher-order_function%29
[fn:gama] https://en.wikipedia.org/wiki/Gauss%E2%80%93Markov_theorem
[fn:intr] http://introtorx.com/
[fn:jplg] JPL Geodynamics Program http://www.jpl.nasa.gov/report/1981.pdf
[fn:just] justified by the fact that $\mathbold{D}$ is a diagonal
matrix that commutes with all other products, therefore its left and right
inverses are equal and can be written as a reciprocal; in fact, $\mathbold{D}$
is a $1\times{1}$ matrix --- effectively a scalar --- in all examples in this paper
[fn:klde] B. Beckman, /Kalman Folding 3: Derivations/, http://vixra.org/abs/1607.0059.
[fn:klf1] B. Beckman, /Kalman Folding, Part 1/, http://vixra.org/abs/1606.0328.
[fn:klf2] B. Beckman, /Kalman Folding 2: Tracking and System Dynamics/, http://vixra.org/abs/1606.0348.
[fn:klf3] B. Beckman, /Kalman Folding 3: Derivations/, http://vixra.org/abs/1607.0059.
[fn:klf4] B. Beckman, /Kalman Folding 4: Streams and Observables/, to appear.
[fn:klfl] B. Beckman, /Kalman Folding, Part 1/, http://vixra.org/abs/1606.0328.
[fn:layi] https://en.wikipedia.org/wiki/Fundamental_theorem_of_software_engineering
[fn:lmbd] Many languages use the keyword /lambda/ for such expressions; Wolfram
uses the name /Function/.
[fn:lmlf] https://en.wikipedia.org/wiki/Lambda_lifting
[fn:lsqo] LINQ's Standard Query Operators
[fn:lssq] https://en.wikipedia.org/wiki/Least_squares
[fn:ltis] http://tinyurl.com/hhhcgca
[fn:matt] https://www.cs.kent.ac.uk/people/staff/dat/miranda/whyfp90.pdf
[fn:mcmc] https://en.wikipedia.org/wiki/Particle_filter
[fn:mond] https://en.wikipedia.org/wiki/Monad
[fn:musc] http://www1.cs.dartmouth.edu/~doug/music.ps.gz
[fn:ndim] https://en.wikipedia.org/wiki/Nondimensionalization
[fn:patt] http://tinyurl.com/j5jzy69
[fn:pseu] http://tinyurl.com/j8gvlug
[fn:rasp] http://www.wolfram.com/raspberry-pi/
[fn:rcrn] https://en.wikipedia.org/wiki/Recurrence_relation
[fn:rsfr] http://rosettacode.org/wiki/Loops/Foreach
[fn:rxbk] http://www.introtorx.com/content/v1.0.10621.0/07_Aggregation.html
[fn:scan] and of Haskell's scans and folds, and Rx's scans and folds, /etc./
[fn:scla] http://tinyurl.com/hhdot36
[fn:scnd] A state-space form containing a position and derivative is commonplace
in second-order dynamics like Newton's Second Law. We usually employ state-space
form to reduce \(n\)-th-order differential equations to first-order differential
equations by stacking the dependent variable on $n-1$ of its derivatives in the
state vector.
[fn:scnl] http://learnyouahaskell.com/higher-order-functions
[fn:stsp] https://en.wikipedia.org/wiki/State-space_representation
[fn:uncl] The initial uncial (lower-case) letter signifies that /we/ wrote this function; it wasn't supplied by Wolfram.
[fn:wfld] http://reference.wolfram.com/language/ref/FoldList.html?q=FoldList
[fn:wlf1] http://tinyurl.com/nfz9fyo
[fn:wlf2] http://rebcabin.github.io/blog/2013/02/04/welfords-better-formula/
[fn:wolf] http://reference.wolfram.com/language/
[fn:zarc] Zarchan and Musoff, /Fundamentals of Kalman Filtering, A Practical
Approach, Fourth Edition/, Ch. 4


